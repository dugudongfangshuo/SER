{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SER.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "q3fOjGrCaVKO",
        "5pCgFY1Gaifl",
        "jdHH69BbaLXN",
        "9WBzQ17TOzg0",
        "X0-Qc37Ipl0K",
        "jBxppdfwApij",
        "wpBkhxw4_JVj"
      ],
      "toc_visible": true,
      "mount_file_id": "18mtCPqT5wTqO3uD2MZUjA-aeXgU5eLK5",
      "authorship_tag": "ABX9TyNFfIhd0+kVeYTmG3I3MUfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dugudongfangshuo/SER/blob/main/SER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhn8x3_hQdyB"
      },
      "source": [
        "# <font color=\"green\">一、配置安装必要的环境和包</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3fOjGrCaVKO"
      },
      "source": [
        "## <font color=\"blue\">安装包</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccE-vwtVuCO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a5936c-606e-440e-aed5-f8c428bef364"
      },
      "source": [
        "!pip install python_speech_features\n",
        "!pip install alive-progress\n",
        "# pytroch安装\n",
        "!pip install torch torchvision torchaudio\n",
        "# 安装调试打印工具ic\n",
        "!pip install icecream\n",
        "!pip install boto3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp37-none-any.whl size=5887 sha256=877a370f632ef57e6ad64e12682c774fb711035111cedf47a9f69b924a0cc514\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n",
            "Collecting alive-progress\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/5c/d63b13cc0bd945b4a9b16e921cc00c5657143f68da4f296bb628b8d1ff17/alive_progress-1.6.2-py3-none-any.whl\n",
            "Installing collected packages: alive-progress\n",
            "Successfully installed alive-progress-1.6.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.0+cu101)\n",
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/9a/4e2e6dbde627ffb8a6d1d4ebc4683edecad1c08099969f1d7760d92175ff/torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.0.0)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.8.0\n",
            "Collecting icecream\n",
            "  Downloading https://files.pythonhosted.org/packages/31/cc/5454531fe9ae123720b496fdea806e282843d6e75e5718a5e8b1d8e5c47f/icecream-2.1.0-py2.py3-none-any.whl\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/62/e9/247023d33dc110117b831cbfe47bb553e10d0edf92297ace745256402d42/asttokens-2.0.4-py2.py3-none-any.whl\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/3d/2c2cf37d6194fa93c35e7ba6ab5aaa841a9b1b788fc322b01e53e0602049/executing-0.5.4-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: colorama, asttokens, executing, icecream\n",
            "Successfully installed asttokens-2.0.4 colorama-0.4.4 executing-0.5.4 icecream-2.1.0\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/6d/1c43d87bfff9e7afb5130629dfb7d57617245eeb4a474bf77f45d637c3a6/boto3-1.17.33-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 10.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.33\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/1c/f922d7fa47cdd6a18c7470252e86f7c4d24e85cb3cdff09486675df3769c/botocore-1.20.33-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 16.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.33->boto3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.33->boto3) (1.15.0)\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, urllib3, botocore, s3transfer, boto3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.17.33 botocore-1.20.33 jmespath-0.10.0 s3transfer-0.3.6 urllib3-1.26.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pCgFY1Gaifl"
      },
      "source": [
        "## <font color=\"blue\">导入包</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsDg8-t8W4kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd9fcae-21ae-4f6f-9ebd-e97e5f393cf0"
      },
      "source": [
        "# 配置matplotlib\n",
        "%matplotlib inline\n",
        "# 导入pytroch相关工具包\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "# 导入代码打印调试工具\n",
        "from icecream import ic\n",
        "# 命令行显示工具\n",
        "from IPython.display import Audio, display\n",
        "# 进度条工具\n",
        "from tqdm.notebook import tqdm\n",
        "# \n",
        "import os\n",
        "#json\n",
        "import json\n",
        "#numpy\n",
        "import numpy as np\n",
        "# 导入tensorflow\n",
        "import tensorflow as tf\n",
        "# 导入libroas\n",
        "import librosa\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Sun Mar 21 16:15:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdHH69BbaLXN"
      },
      "source": [
        "## <font color=\"#FF8C00\">临时添加安装包的位置</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlBIfxJqaBB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "362cd922-6202-43f0-b24a-84e1e6ed2a8e"
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (54.1.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (20.9)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.26.4\n",
            "    Uninstalling urllib3-1.26.4:\n",
            "      Successfully uninstalled urllib3-1.26.4\n",
            "Successfully installed urllib3-1.25.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp7l95g0faF2"
      },
      "source": [
        "#三、把Iemocap音频数据按照感情类别进行分类"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrZecRGqMpME"
      },
      "source": [
        "### 设置全局参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJMvvbSaJoYD",
        "outputId": "f1cd1c12-62d2-4dc7-baf0-6f2353d1c080"
      },
      "source": [
        "from datetime import time\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "# 导入代码打印调试工具\n",
        "from icecream import ic\n",
        "# 命令行显示工具\n",
        "import IPython.display as ipd\n",
        "# 进度条工具\n",
        "from tqdm import tqdm\n",
        "#\n",
        "import os\n",
        "#json\n",
        "import json\n",
        "#numpy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "##################### 参数 ##########################################################\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "rootdir = \"/content/drive/MyDrive/data/emotion/IEMOCAP\"\n",
        "rootdirs = \"/content/drive/MyDrive/data/emotion/\"\n",
        "# rootdirs = \".\"\n",
        "# 数据集\n",
        "Neutral = [] #neu\n",
        "Anger = [] #ang\n",
        "Frustration = [] #fru\n",
        "Surprise = [] #sur\n",
        "Excited = [] #exc\n",
        "Happiness = [] #hap\n",
        "Sadness = [] # sad\n",
        "fear = [] # fea\n",
        "xxx = [] #xxx\n",
        "# 数据个数统计\n",
        "num_Neutral = 0 #neu\n",
        "num_Anger = 0 #ang\n",
        "num_Frustration = 0 #fru\n",
        "num_Surprise = 0 #sur\n",
        "num_Excited = 0 #exc\n",
        "num_Happiness = 0 #hap\n",
        "num_Sadness = 0 # sad\n",
        "num_fear = 0 # fea\n",
        "num_xxx = 0 #xxx\n",
        "# json文件名\n",
        "file_json=[]\n",
        "file_Neutral = rootdirs + \"/mydata/neu.json\" #neu\n",
        "file_Anger = rootdirs + \"/mydata/ang.json\" #ang\n",
        "file_Frustration = rootdirs + \"/mydata/fru.json\" #fru\n",
        "file_Surprise = rootdirs + \"/mydata/sur.json\" #sur\n",
        "file_Excited = rootdirs + \"/mydata/exc.json\" #exc\n",
        "file_Happiness = rootdirs + \"/mydata/hap.json\" #hap\n",
        "file_Sadness = rootdirs + \"/mydata/sad.json\" # sad\n",
        "file_fear = rootdirs + \"/mydata/fea.json\" # fea\n",
        "file_xxx = rootdirs + \"/mydata/xxx.json\" #xxx\n",
        "# 把文件，数据变量,和label类型都对应一起放入到数组里\n",
        "file_json=[file_Neutral,file_Anger,file_Frustration,file_Surprise,file_Excited,file_Happiness,file_Sadness,file_fear,file_xxx]\n",
        "data_all=[Neutral,Anger,Frustration,Surprise,Excited,Happiness,Sadness,fear,xxx]\n",
        "needtype=['neu','ang','fru','sur','exc','hap','sad','fea','xxx']\n",
        "# 定义一下截取的数据长度\n",
        "max_len = 300\n",
        "ifjiequ = False #定义一下是否截取\n",
        "# 指定要读取的文件类型，1为是，0为否\n",
        "needread=[ 1,  #1neu\n",
        "      1,  #2ang\n",
        "      0,  #3fru\n",
        "      0,  #4sur\n",
        "      0,  #5exc\n",
        "      1,  #6hap\n",
        "      1,  #7sad\n",
        "      0,  #8fea\n",
        "      0   #9xxx\n",
        "      ]\n",
        "# 指定要读取的数目是多少\n",
        "number= [ 100,  #1neu\n",
        "      100,  #2ang\n",
        "      100,  #3fru\n",
        "      100,  #4sur\n",
        "      100,  #5exc\n",
        "      100,  #6hap\n",
        "      100,  #7sad\n",
        "      100,  #8fea\n",
        "      100   #9xxx\n",
        "      ]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9K53v8yLOJ6"
      },
      "source": [
        "### 按类别来保存音频文件到各个json文件夹里"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoGuK-VEJExq"
      },
      "source": [
        "# 获取频谱特征\n",
        "def get_wav_specgram(filename):\n",
        "  waveform, sample_rate = torchaudio.load(filename)\n",
        "  specgram = torchaudio.transforms.Spectrogram()(waveform)\n",
        "  if waveform.size(0) != 1:\n",
        "    ic(\"通道数不为1，请注意\")\n",
        "  return specgram[0]\n",
        "# 把相关的音频数据整理提取到相同的长度，返回相关参数，保存为json\n",
        "def cut_padding_all_to_same(filename,len):\n",
        "  specgram = get_wav_specgram(filename)\n",
        "  begin = []\n",
        "  end = []\n",
        "  ispadding = 0\n",
        "  key = 0\n",
        "  # new_specgram = []\n",
        "  if ifjiequ== True:\n",
        "    # 小于指定的长度进行补零\n",
        "    if specgram.t().shape[0]<=len:\n",
        "      # new_specgram = np.pad(specgram, ((0, 0),(0, max_len - specgram.shape[1]),), 'constant', constant_values=0)\n",
        "      ispadding = 1\n",
        "      begin.append(0)\n",
        "      ends = specgram.shape[1]\n",
        "      end.append(ends)\n",
        "      return  ispadding,begin,end,1\n",
        "    # 大于指定长度的按照指定长度进行切割\n",
        "    else:\n",
        "      for i in range(int(specgram.shape[1]//(len/2))-1):\n",
        "        begins = len * i\n",
        "        ends = begins + len\n",
        "        if ends>specgram.shape[1]:\n",
        "          break\n",
        "        # new_specgram += [specgram[:,begin:end].numpy()]\n",
        "        begin.append(begins)\n",
        "        end.append(ends)\n",
        "        key+=1\n",
        "      return ispadding,begin,end,key\n",
        "  else:\n",
        "    begin.append(0)\n",
        "    ends = specgram.shape[1]\n",
        "    end.append(ends)\n",
        "    return ispadding,begin,end,1\n",
        "# 把数据保存为json文件\n",
        "def get_json():\n",
        "  global num_Neutral    # neu\n",
        "  global num_Anger    # ang\n",
        "  global num_Frustration    # fru\n",
        "  global num_Surprise    # sur\n",
        "  global num_Excited    # exc\n",
        "  global num_Happiness    # hap\n",
        "  global num_Sadness    # sad\n",
        "  global num_fear    # fea\n",
        "  global num_xxx    # xxx\n",
        "  for speaker in tqdm(os.listdir(rootdir),desc=\"正在按照感情类别分类音频文件：\"):\n",
        "    # 对应的标注文件夹\n",
        "    emoevl = os.path.join(rootdir, speaker, 'dialog/EmoEvaluation')\n",
        "    for subemo in os.listdir(emoevl):\n",
        "      if subemo[2]=='s':\n",
        "        # 打开文件进行内容读取：\n",
        "        with open(os.path.join(rootdir, speaker, 'dialog/EmoEvaluation/'+subemo), 'r') as emot_to_read:\n",
        "          while True:\n",
        "            line = emot_to_read.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            if (line[0] == '['):\n",
        "                t = line.split()\n",
        "\n",
        "                waveform, sample_rate = torchaudio.load(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'))\n",
        "                if waveform.shape[1] < 48000:\n",
        "                  continue\n",
        "\n",
        "\n",
        "                if t[4] == 'neu':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    Neutral.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),\n",
        "                    \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_Neutral +=1\n",
        "                if t[4] == 'ang':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    Anger.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0]+'/'+ t[3] + '.wav'),\n",
        "                    \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_Anger +=1\n",
        "                if t[4] == 'fru':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    Frustration.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0]+'/'+ t[3] + '.wav'),\n",
        "                      \"wav_spec_begin\": begin[i],\n",
        "                      \"wav_spec_end\": end[i],\n",
        "                      \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_Frustration +=1\n",
        "                if t[4] == 'sur':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    Surprise.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0]+'/'+ t[3] + '.wav'),\n",
        "                     \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_Surprise +=1\n",
        "                if t[4] == 'exc':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    Excited.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0]+'/'+ t[3] + '.wav'),\n",
        "                    \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_Excited +=1\n",
        "                if t[4] == 'hap':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    Happiness.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0]+'/'+ t[3] + '.wav'),\n",
        "                    \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_Happiness +=1\n",
        "                if t[4] == 'sad':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    Sadness.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0]+'/'+ t[3] + '.wav'),\n",
        "                     \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_Sadness +=1\n",
        "                if t[4] == 'fea':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    fear.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3] + '.wav'),\n",
        "                     \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_fear +=1\n",
        "                if t[4] == 'xxx':\n",
        "                  ispad,begin , end,v = cut_padding_all_to_same(os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3]+'.wav'),max_len)\n",
        "                  for i in range(v):\n",
        "                    xxx.append({\n",
        "                    \"file\": os.path.join(rootdir, speaker, 'sentences/wav/'+ os.path.splitext(subemo)[0] +'/'+ t[3] + '.wav'),\n",
        "                     \"wav_spec_begin\": begin[i],\n",
        "                    \"wav_spec_end\": end[i],\n",
        "                    \"wav_spec_pad\": ispad,\n",
        "                    \"emotion\": t[4]\n",
        "                    })\n",
        "                    num_xxx +=1\n",
        "\n",
        "  result_all = \"Neutral 的数量是\"+ str(num_Neutral) +\"\\n\"\n",
        "  result_all += \"Anger 的数量是\"+ str(num_Anger) +\"\\n\"\n",
        "  result_all += \"Frustration 的数量是\"+ str(num_Frustration) +\"\\n\"\n",
        "  result_all += \"Surprise 的数量是\"+ str(num_Surprise) +\"\\n\"\n",
        "  result_all += \"Excited 的数量是\"+ str(num_Excited) +\"\\n\"\n",
        "  result_all += \"Happiness 的数量是\"+ str(num_Happiness) +\"\\n\"\n",
        "  result_all += \"Sadness 的数量是\"+ str(num_Sadness) +\"\\n\"\n",
        "  result_all += \"fear 的数量是\"+ str(num_fear) +\"\\n\"\n",
        "  result_all += \"xxx 的数量是\"+ str(num_xxx) +\"\\n\"\n",
        "  print(result_all)\n",
        "\n",
        "  for i in tqdm(file_json,desc=\"json数据保存进度\"):\n",
        "    with open(i, 'w+', encoding=\"utf8\") as f:\n",
        "        json.dump(data_all[file_json.index(i)], f, ensure_ascii=False, indent=2)\n",
        "# 进行标签编号\n",
        "def make_lable(need_read):\n",
        "  # 标签信息\n",
        "  lable = -1\n",
        "  n_lable = [0,0,0,0,0,0,0,0,0]\n",
        "  indexs = 0\n",
        "  for tpye in need_read:\n",
        "    if need_read[indexs] == 1:\n",
        "      lable += 1\n",
        "      n_lable[indexs] = lable\n",
        "    indexs += 1\n",
        "  return n_lable\n",
        "# 读取json文件返回一个tuple等待Dataset进一步的处理数据。\n",
        "def read_jsonfile(number,needread):\n",
        "  tuples = []\n",
        "  lables = make_lable(needread)\n",
        "  indexs = 0\n",
        "  type = 0\n",
        "  for i in needread:\n",
        "    # 确定要读取\n",
        "    if needread[indexs] == 1:\n",
        "      # 读取对应的文件\n",
        "      with open(file_json[indexs],'r',encoding='utf8')as fp:\n",
        "        json_data = json.load(fp)\n",
        "      # 循环json数组处理数据为元组\n",
        "      indexsofnumber = 0\n",
        "      for k in json_data:\n",
        "        if indexsofnumber<number[indexs]:\n",
        "          tuples.append([lables[indexs],json_data[indexsofnumber][\"file\"],json_data[indexsofnumber][\"wav_spec_begin\"],json_data[indexsofnumber][\"wav_spec_end\"],json_data[indexsofnumber][\"wav_spec_pad\"]])\n",
        "          indexsofnumber +=1\n",
        "      type +=1\n",
        "    indexs += 1\n",
        "  return tuples,type\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oafJVG2R73mY"
      },
      "source": [
        "#get_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pUY2A2gNN7c"
      },
      "source": [
        "### 读取不同类别json文件里的数据到一个列表中，构建我们的数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bdkEg0uNBJ8"
      },
      "source": [
        "# 指定要读取的文件类型，1为是，0为否\n",
        "needread=[ 1,  #1neu\n",
        "      1,  #2ang\n",
        "      0,  #3fru\n",
        "      0,  #4sur\n",
        "      0,  #5exc\n",
        "      1,  #6hap\n",
        "      1,  #7sad\n",
        "      0,  #8fea\n",
        "      0   #9xxx\n",
        "      ]\n",
        "# 指定要读取的数目是多少\n",
        "number= [ 351,  #1neu\n",
        "      351,  #2ang\n",
        "      351,  #3fru\n",
        "      351,  #4sur\n",
        "      351,  #5exc\n",
        "      351,  #6hap\n",
        "      351,  #7sad\n",
        "      351,  #8fea\n",
        "      351   #9xxx\n",
        "      ]\n",
        "# get_json()\n",
        "# 构建一个类可以生成一个包含测试集和验证集的列表\n",
        "def generate_train_val_data(trainbi):\n",
        "  '''\n",
        "  输入的是训练集的比重\n",
        "  '''\n",
        "  data,types = read_jsonfile(number, needread)\n",
        "  np.random.shuffle(data)\n",
        "  train_data = data[0:int(len(data)*trainbi)]\n",
        "  val_data = data[int(len(data)*trainbi):]\n",
        "  return train_data,val_data,types\n",
        " \n",
        "train_data,val_data,types = generate_train_val_data(0.9)\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGqKy98xnkDL"
      },
      "source": [
        "### 构建一个pytorch的数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGNDLmgVnpBB"
      },
      "source": [
        "batch_size=10\n",
        "class train_dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,train_data):\n",
        "    super(train_dataset, self).__init__()\n",
        "    self.data = train_data\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # 读取数据进行处理获得标签信息和对应的音频数据\n",
        "    # 读取数据进行处理获得标签信息和对应的音频数据\n",
        "    lable = self.data[index][0]\n",
        "    file = self.data[index][1]\n",
        "    waveform, sample_rate = torchaudio.load(file)\n",
        "\n",
        "    n_fft = 1024\n",
        "    win_length = None\n",
        "    hop_length = 512\n",
        "\n",
        "    # define transformation\n",
        "    spectrogram = T.Spectrogram(\n",
        "      n_fft=n_fft,\n",
        "      win_length=win_length,\n",
        "      hop_length=hop_length,\n",
        "      center=True,\n",
        "      pad_mode=\"reflect\",\n",
        "      power=2.0,\n",
        "    )\n",
        "    spec = spectrogram(waveform[0][0:48000])\n",
        "    x = torch.stack((spec, spec, spec))\n",
        "\n",
        "\n",
        "    return x, lable\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "class val_dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,val_data):\n",
        "    super(val_dataset, self).__init__()\n",
        "    self.data = val_data\n",
        "  def __getitem__(self, index):\n",
        "    # 读取数据进行处理获得标签信息和对应的音频数据\n",
        "    lable = self.data[index][0]\n",
        "    file = self.data[index][1]\n",
        "    waveform, sample_rate = torchaudio.load(file)\n",
        "\n",
        "    n_fft = 1024\n",
        "    win_length = None\n",
        "    hop_length = 512\n",
        "\n",
        "    # define transformation\n",
        "    spectrogram = T.Spectrogram(\n",
        "      n_fft=n_fft,\n",
        "      win_length=win_length,\n",
        "      hop_length=hop_length,\n",
        "      center=True,\n",
        "      pad_mode=\"reflect\",\n",
        "      power=2.0,\n",
        "    )\n",
        "    spec = spectrogram(waveform[0][0:48000])\n",
        "    x = torch.stack((spec, spec, spec))\n",
        "    return x, lable\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "traindataset = train_dataset(train_data)\n",
        "valdataset = val_dataset(val_data)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=traindataset,\n",
        "                        batch_size=batch_size,\n",
        "                        drop_last=True,\n",
        "                        shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=valdataset,\n",
        "                        batch_size=batch_size,\n",
        "                        drop_last=True,\n",
        "                        shuffle=False,)\n",
        "# for i,x in enumerate(traindataset):\n",
        "#   print(x[0].shape)\n",
        "# # len(traindataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WBzQ17TOzg0"
      },
      "source": [
        "### 对数据进行详细分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d43fTMtUpe5S"
      },
      "source": [
        "# dataone = 0\n",
        "# datwo = 0\n",
        "# dathree = 0\n",
        "# datfour = 0\n",
        "# dafive = 0\n",
        "\n",
        "# waveform, sample_rate = torchaudio.load(train_data[0][1])\n",
        "# print(waveform.shape)\n",
        "# n_fft = 1024\n",
        "# win_length = None\n",
        "# hop_length = 512\n",
        "\n",
        "# # define transformation\n",
        "# spectrogram = T.Spectrogram(\n",
        "#     n_fft=n_fft,\n",
        "#     win_length=win_length,\n",
        "#     hop_length=hop_length,\n",
        "#     center=True,\n",
        "#     pad_mode=\"reflect\",\n",
        "#     power=2.0,\n",
        "# )\n",
        "\n",
        "# spectrogram1 = T.Spectrogram(\n",
        "#     n_fft=n_fft,\n",
        "#     win_length=win_length,\n",
        "#     hop_length=hop_length,\n",
        "#     center=True,\n",
        "#     pad_mode=\"reflect\",\n",
        "#     power=1.0,\n",
        "# )\n",
        "\n",
        "# spectrogram2 = T.Spectrogram(\n",
        "#     n_fft=n_fft,\n",
        "#     win_length=win_length,\n",
        "#     hop_length=hop_length,\n",
        "#     center=True,\n",
        "#     pad_mode=\"reflect\",\n",
        "#     power=None,\n",
        "# )\n",
        "# # Perform transformation\n",
        "# spec = spectrogram(waveform)\n",
        "# spec1 = spectrogram1(waveform)\n",
        "# spec2 = spectrogram2(waveform)\n",
        "# plot_spectrogram(spec[0], title='torchaudio')\n",
        "# plot_spectrogram(spec1[0], title='torchaudio1')\n",
        "# print(spec.shape)\n",
        "# print(spec1.shape)\n",
        "# print(spec2.shape)\n",
        "# plot_spectrogram(np.imag(spec2[0]), title='torchaudio2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0-Qc37Ipl0K"
      },
      "source": [
        "### 构建一个tensorflow数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xue2FWL-pqfr"
      },
      "source": [
        "# def preprocess_dataset(files):\n",
        "#   files = np.array(files)\n",
        "#   files_ds = tf.data.Dataset.from_tensor_slices(files[:,1])\n",
        "#   files_dslable = tf.data.Dataset.from_tensor_slices(files[:,0])\n",
        "#   return files_ds,files_dslable\n",
        "\n",
        "# val_ds,val_lable = preprocess_dataset(train_data)\n",
        "# train_ds,train_lable = preprocess_dataset(val_data)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIurRJhquRVq"
      },
      "source": [
        "# a = train_ds.take(1)\n",
        "# list(a.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBxppdfwApij"
      },
      "source": [
        "### 构建我们的模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck5RAGjyB66M"
      },
      "source": [
        "使用卷积神经网络对图谱进行特征提取"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UhPyzIAAjZv"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class my_resnet50(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(my_resnet50, self).__init__()\n",
        "        self.resnet50 = models.resnet50(pretrained=True)\n",
        "        self.classfier = model = nn.Sequential(OrderedDict([\n",
        "          ('c_layer1', nn.Linear(2048,1024)),\n",
        "          ('c_relu1', nn.ReLU()),\n",
        "          ('c_layer2', nn.Linear(1024,512)),\n",
        "          ('c_relu2', nn.ReLU()),\n",
        "          ('c_layer3', nn.Linear(512, 128)),\n",
        "          ('c_relu3', nn.ReLU()),\n",
        "          ('c_layer4', nn.Linear(128, 4)),\n",
        "          ('c_relu5', nn.ReLU()),\n",
        "          ('c_LogSoftmax', nn.LogSoftmax(dim=1)),\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 去掉最后一层\n",
        "        for idx, m in enumerate(self.resnet50.children()):\n",
        "            if idx not in [9]:\n",
        "               x =  m(x)\n",
        "        # 加上一个分类网络对结果进行分类\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classfier(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lGSsM9d6Aa6"
      },
      "source": [
        "### 进行模型训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eVwj05I5_yd"
      },
      "source": [
        "# 定义一个通用的训练过程\n",
        "import copy\n",
        "import time\n",
        "from sched import scheduler\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "def train_model(model,loss_fc,optimizer,scheduler,dataloaders,datalens,device,num_epochs=10):\n",
        "    '''\n",
        "    :param model: 训练的模型\n",
        "    :param loss_fc: 损失函数\n",
        "    :param optimizer: 优化器\n",
        "    :param scheduler: 调整优化器\n",
        "    :param dataloaders: 数据集字典格式['train':dataloader,'val':dataloader]\n",
        "    :param datalens: 数据集字典格式['train':int,'val':int]\n",
        "    :param device: 设备变量\n",
        "    :param num_epochs: 循环的代数，默认为10\n",
        "    :return: 返回最好的模型权重\n",
        "    '''\n",
        "    PATH = './model_weight/'\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # 迭代次数\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase，每一代都有一次训练一次验证的过程\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.把所有数据输入模型进行训练\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients初始化优化器\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward，前向传播，根据数据集开启梯度计算\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    # 得到预测结果，数字最大的序号，标签编码号要从0开始\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    loss = loss_fc(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase，反向传播更新参数\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics，统计损失数据和正确率\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # 所有数据循环完，根据当前代数使用scheduler调整优化器参数\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            # 计算一下平均损失，和平均准确率\n",
        "            epoch_loss = running_loss / datalens[phase]\n",
        "            epoch_acc = running_corrects.double() / datalens[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # 保存权重\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    # 保存整个模型\n",
        "    torch.save(model, PATH)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vOb6QlJ6OQQ"
      },
      "source": [
        "def IEMOCAP_SER_Restnet50_Train():\n",
        "    # 找设备\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # 构建数据集\n",
        "    train_data, val_data, types = generate_train_val_data(0.9)\n",
        "    batch_size = 10\n",
        "    traindataset = train_dataset(train_data)\n",
        "    valdataset = val_dataset(val_data)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=traindataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               drop_last=True,\n",
        "                                               shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset=valdataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             drop_last=True,\n",
        "                                             shuffle=False, )\n",
        "    dataloaders = {'train':train_loader,'val':val_loader}\n",
        "    datalen = {'train':len(traindataset),'val':len(valdataset)}\n",
        "    # 引入模型\n",
        "    model = my_resnet50()\n",
        "    model.to(device)\n",
        "    # 构建损失函数\n",
        "    criterion = nn.NLLLoss()\n",
        "    # 构建优化函数\n",
        "    optimizer_ft = optim.Adam(model.parameters(), lr=0.01)\n",
        "    # 设置scheduler调整优化器的变化\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.01)\n",
        "    # 进行训练\n",
        "    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, dataloaders,datalen, device, 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUhQTdW6n1q"
      },
      "source": [
        "IEMOCAP_SER_Restnet50_Train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpBkhxw4_JVj"
      },
      "source": [
        "# 构建我们自己的数据集类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LloMgyEL_Vow"
      },
      "source": [
        "'''\n",
        "使用tf.data来构建我们自己的dataset\n",
        "'''\n",
        "import wave\n",
        "import numpy as np\n",
        "import python_speech_features as ps\n",
        "import os\n",
        "import glob\n",
        "import _pickle as cPickle\n",
        "import tensorflow as tf\n",
        "from alive_progress import alive_bar\n",
        "from tqdm.notebook import tqdm\n",
        "'''\n",
        "使用IEMOCAP进行四种感情的识别\n",
        "'''\n",
        "class mydataset_IEMOCAP_FOUR():\n",
        "    def __init__(self):\n",
        "        # 定义数据集的根目录\n",
        "        self.rootdir = 'drive/MyDrive/data/emotion/IEMOCAP'\n",
        "        # self.rootdir ='../data/IEMOCAP'\n",
        "        # 定义过滤器个数，即特征向量的维度\n",
        "        self.filter_num = 40\n",
        "        # 定义数据集\n",
        "        self.dataset = None\n",
        "        # 记录每个样本的标签信息\n",
        "        self.train_label = None\n",
        "        # 定义一个超参数\n",
        "        self.eps = 1e-5\n",
        "\n",
        "        # 统计每个集合种不同类别的感情特征所拥有的数目的\n",
        "        self.train_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.test_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.valid_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "    # 进行数据标签生成\n",
        "    def generate_label(self, emotion):\n",
        "        label = -1\n",
        "        if (emotion == 'ang'):\n",
        "            label = 0\n",
        "        elif (emotion == 'sad'):\n",
        "            label = 1\n",
        "        elif (emotion == 'hap'):\n",
        "            label = 2\n",
        "        elif (emotion == 'neu'):\n",
        "            label = 3\n",
        "        elif (emotion == 'fear'):\n",
        "            label = 4\n",
        "        else:\n",
        "            label = 5\n",
        "        return label\n",
        "    # 计算MFCC\n",
        "    def compute_logfbank(self,data,rate):\n",
        "        mel_spec = ps.logfbank(data, rate, nfilt=self.filter_num)\n",
        "        return mel_spec\n",
        "    # 计算delta\n",
        "    def comput_delta(self,mel_spec):\n",
        "        # 直接在log Mels上做一阶差分和二阶差分的\n",
        "        delta = ps.delta(mel_spec, 2)\n",
        "        return delta\n",
        "    # 对计算的三层数据结果进行拼接融合成一个batch,然后在batch维度上进行拼接\n",
        "    def combine(self, one, two, three):\n",
        "        # 进行三层的合并和调整\n",
        "        x = tf.expand_dims(tf.transpose(tf.stack([one, two, three]), perm=[1, 2, 0]), axis=0)\n",
        "        # 和上一个数据进行拼接\n",
        "        if self.dataset == None:\n",
        "            self.dataset = x\n",
        "        else:\n",
        "            self.dataset = tf.concat([x, self.dataset], 0)\n",
        "    # 读取一个wav文件返回的是所有采样点，帧的时间，和采样率\n",
        "    def read_file(self, filename):\n",
        "        # 注意使用二进制模式读wav音频文件\n",
        "        with wave.open(filename, 'rb') as f:\n",
        "            # 一次性返回所有格式信息——nchannels, sampwidth, framerate(采样率), nframes(# 帧数), comptype, compname\n",
        "            params = f.getparams()\n",
        "            # 解析各种音频数据\n",
        "            nchannels, sampwidth, framerate, nframes = params[:4]\n",
        "            # 读取并返回以 bytes 对象表示的最多 n 帧音频。\n",
        "            buffer_data = f.readframes(nframes)\n",
        "            # 把buffer数据格式化为short\n",
        "            wavedata = np.frombuffer(buffer_data, dtype=np.short)\n",
        "            # # 每个点的序号乘以我们的采样率的倒数（就是采样一个点的时间）来计算获取每个时间帧以查的时间\n",
        "            # time = np.arange(0, nframes) * (1.0 / framerate)\n",
        "            f.close()\n",
        "        return wavedata, framerate\n",
        "    # 将所有的计算特征的步骤合并成一个函数\n",
        "    def create_data(self,sort,data,rate,begin,end,emotion,train_num):\n",
        "        logfbank_feature = self.compute_logfbank(data,rate)\n",
        "        delta_logfbank_feature1 = self.comput_delta(logfbank_feature)\n",
        "        delta_logfbank_feature2 = self.comput_delta(delta_logfbank_feature1)\n",
        "        if sort==1:\n",
        "            # 特征合并\n",
        "            logfbank_feature_temp = np.pad(logfbank_feature, ((0, 300 - logfbank_feature.shape[0]), (0, 0)), 'constant',\n",
        "                          constant_values=0)\n",
        "            delta_logfbank_feature1_temp = np.pad(delta_logfbank_feature1, ((0, 300 - delta_logfbank_feature1.shape[0]), (0, 0)), 'constant',\n",
        "                             constant_values=0)\n",
        "            delta_logfbank_feature2_temp = np.pad(delta_logfbank_feature2, ((0, 300 - delta_logfbank_feature2.shape[0]), (0, 0)), 'constant',\n",
        "                             constant_values=0)\n",
        "            self.combine(tf.convert_to_tensor(logfbank_feature_temp),tf.convert_to_tensor(delta_logfbank_feature1_temp),tf.convert_to_tensor(delta_logfbank_feature2_temp))\n",
        "            # 标签记录\n",
        "            em = self.generate_label(emotion)\n",
        "            if self.train_label is None:\n",
        "                self.train_label = np.array([em])\n",
        "            else:\n",
        "                self.train_label = np.append(self.train_label,[em])\n",
        "            self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "\n",
        "        elif sort==2:\n",
        "            # 特征合并\n",
        "            logfbank_feature_temp = logfbank_feature[begin:end, :]\n",
        "            delta_logfbank_feature1_temp = delta_logfbank_feature1[begin:end, :]\n",
        "            delta_logfbank_feature2_temp = delta_logfbank_feature2[begin:end, :]\n",
        "            self.combine(tf.convert_to_tensor(logfbank_feature_temp), tf.convert_to_tensor(delta_logfbank_feature1_temp), tf.convert_to_tensor(delta_logfbank_feature2_temp))\n",
        "            # 标签记录\n",
        "            em = self.generate_label(emotion)\n",
        "            if self.train_label is None:\n",
        "                self.train_label = np.array([em])\n",
        "            else:\n",
        "                self.train_label = np.append(self.train_label, [em])\n",
        "            self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "    # 遍历数据集的公用函数\n",
        "    def common_proccess(self):\n",
        "        train_num = 0\n",
        "     \n",
        "        for speaker in tqdm(os.listdir(self.rootdir),desc=\"总结文件夹处理进度\"):\n",
        "            sub_dir = os.path.join(self.rootdir, speaker, 'sentences/wav')\n",
        "            emoevl = os.path.join(self.rootdir, speaker, 'dialog/EmoEvaluation')\n",
        "            # 遍历五个对话集\n",
        "            for sess in tqdm(os.listdir(sub_dir),desc=\"   五个子文件夹处理进度：\"):\n",
        "                # 先读取音频的标记存储到字典里\n",
        "                emotdir = emoevl + '/' + sess + '.txt'\n",
        "                emot_map = {}\n",
        "                with open(emotdir, 'r') as emot_to_read:\n",
        "                    while True:\n",
        "                        line = emot_to_read.readline()\n",
        "                        if not line:\n",
        "                            break\n",
        "                        if (line[0] == '['):\n",
        "                            t = line.split()\n",
        "                            emot_map[t[3]] = t[4]\n",
        "                # 读取音频文件\n",
        "                file_dir = os.path.join(sub_dir, sess, '*.wav')\n",
        "                files = glob.glob(file_dir)\n",
        "\n",
        "                for filename in files:\n",
        "                    wavname = filename.split(\"/\")[-1][:-4]\n",
        "                    if \"(\" in wavname:\n",
        "                              continue \n",
        "                    emotion = emot_map[wavname]\n",
        "                    if (emotion in ['hap', 'ang', 'neu', 'sad']):\n",
        "                        # 开始读取音频文件\n",
        "                        data, rate = self.read_file(filename)\n",
        "                        mel_spec = ps.logfbank(data, rate, nfilt=self.filter_num)\n",
        "                        time = mel_spec.shape[0]\n",
        "\n",
        "                        if (time <= 300):\n",
        "                            self.create_data(1, data, rate, 0, 0, emotion, train_num)\n",
        "                            train_num = train_num + 1\n",
        "\n",
        "                        else:\n",
        "                            if (emotion in ['ang', 'neu', 'sad']):\n",
        "                                for i in range(2):\n",
        "                                    if (i == 0):\n",
        "                                        begin = 0\n",
        "                                        end = begin + 300\n",
        "                                    else:\n",
        "                                        begin = time - 300\n",
        "                                        end = time\n",
        "\n",
        "                                    self.create_data(2, data, rate, begin, end, emotion, train_num)\n",
        "                                    train_num = train_num + 1\n",
        "\n",
        "                            else:\n",
        "                                frames = divmod(time - 300, 100)[0]\n",
        "                                for i in range(frames + 1):\n",
        "                                    # todo 更新下一个数据插入的位置\n",
        "                                    begin = 100 * i\n",
        "                                    end = begin + 300\n",
        "\n",
        "                                    self.create_data(2, data, rate, begin, end, emotion, train_num)\n",
        "                                    train_num = train_num + 1\n",
        "        return train_num\n",
        "\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "\n",
        "        train_nums = self.common_proccess()\n",
        "\n",
        "        ## 1.获取到一维的标签列表，将他转化为dataset的数据类型\n",
        "        tf_label = self.train_label.T.squeeze()\n",
        "        label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(tf_label, tf.int64))\n",
        "        ## 2.获取到数据样本\n",
        "        ### 2.1. 对三个特征层进行标准化处理\n",
        "\n",
        "        ### 2.2. 把数据集转换为dataset类型\n",
        "\n",
        "        sampledata = tf.data.Dataset.from_tensor_slices(self.dataset)\n",
        "        ## 3把两个dataset合并构成一个dataset\n",
        "        ds = tf.data.Dataset.zip((sampledata, label_ds))\n",
        "        ## 4.划分训练集和验证集合\n",
        "        train_data = ds.skip(int(train_nums * 0.3)).shuffle(int(train_nums - train_nums * 0.3)).batch(16,\n",
        "                                                                                                                     drop_remainder=True)\n",
        "        val_data = ds.take(int(train_nums * 0.3)).shuffle(int(train_nums - train_nums * 0.3)).batch(16,\n",
        "                                                                                                                   drop_remainder=True)\n",
        "        print(\"训练样本数量\")\n",
        "        print(train_nums)\n",
        "        return train_data, val_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxG1ej5bxrXD"
      },
      "source": [
        "'''\n",
        "使用tf.data来构建我们自己的dataset\n",
        "'''\n",
        "import wave\n",
        "import numpy as np\n",
        "import python_speech_features as ps\n",
        "import os\n",
        "import glob\n",
        "import _pickle as cPickle\n",
        "import tensorflow as tf\n",
        "class mydataset():\n",
        "    def __init__(self):\n",
        "\n",
        "        # 定义数据集的根目录\n",
        "        self.rootdir = 'drive/MyDrive/data/emotion/IEMOCAP'\n",
        "        # 定义测试数据集的样本数目\n",
        "        self.test_num = 420  # the number of test 2s segments\n",
        "        # 定义验证数据集的样本数目\n",
        "        self.valid_num = 436\n",
        "        # 定义训练数据集的样本个数\n",
        "\n",
        "        # 定义过滤器个数，即特征向量的维度\n",
        "        self.filter_num = 40\n",
        "\n",
        "        # 定义测试数据集合使用的音频数\n",
        "        self.tnum = 259  # the number of test utterance\n",
        "        # 定义验证数据集合使用音频数目\n",
        "        self.vnum = 298\n",
        "\n",
        "\n",
        "        # 2774\n",
        "        self.hapnum = 434  # 2\n",
        "        self.angnum = 433  # 0\n",
        "        self.neunum = 1262  # 3\n",
        "        self.sadnum = 799  # 1\n",
        "\n",
        "        self.pernum = 300  # np.min([hapnum,angnum,sadnum,neunum])\n",
        "        # 记录每个测试音频使用的段落数目\n",
        "        self.pernums_test = np.arange(self.tnum)  # remerber each utterance contain how many segments\n",
        "        # 记录每个验证音频使用的段落数目\n",
        "        self.pernums_valid = np.arange(self.vnum)\n",
        "\n",
        "        self.train_nums = self.get_numof_sample()\n",
        "        # 定义三层矩阵用来 分别存储三种特征值\n",
        "        self.traindata1 = np.empty((self.train_nums * 300, self.filter_num), dtype=np.float32)\n",
        "        self.traindata2 = np.empty((self.train_nums * 300, self.filter_num), dtype=np.float32)\n",
        "        self.traindata3 = np.empty((self.train_nums * 300, self.filter_num), dtype=np.float32)\n",
        "\n",
        "        # 三个特征层的均值和方差\n",
        "        self.mean1 = np.mean(self.traindata1, axis=0)  # axis=0纵轴方向,按列求均值\n",
        "        self.std1 = np.std(self.traindata1, axis=0)\n",
        "        self.mean2 = np.mean(self.traindata2, axis=0)  # axis=0纵轴方向求均值\n",
        "        self.std2 = np.std(self.traindata2, axis=0)\n",
        "        self.mean3 = np.mean(self.traindata3, axis=0)  # axis=0纵轴方向求均值\n",
        "        self.std3 = np.std(self.traindata3, axis=0)\n",
        "\n",
        "        # 记录每个样本的标签信息\n",
        "        self.train_label = np.empty((self.train_nums, 1), dtype=np.int8)\n",
        "        self.Test_label = np.empty((self.test_num, 1), dtype=np.int8)\n",
        "        self.Valid_label = np.empty((self.valid_num, 1), dtype=np.int8)\n",
        "\n",
        "        # 记录每个音频文件的标签信息\n",
        "        self.test_label = np.empty((self.tnum, 1), dtype=np.int8)\n",
        "        self.valid_label = np.empty((self.vnum, 1), dtype=np.int8)\n",
        "\n",
        "\n",
        "        # 定义一个超参数\n",
        "        self.eps = 1e-5\n",
        "\n",
        "        #统计每个集合种不同类别的感情特征所拥有的数目的\n",
        "        self.train_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.test_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.valid_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "\n",
        "    # 读取一个wav文件返回的是所有采样点，帧的时间，和采样率\n",
        "    def read_file(self, filename):\n",
        "        # 注意使用二进制模式读wav音频文件\n",
        "        with wave.open(filename,'rb') as f:\n",
        "            # 一次性返回所有格式信息——nchannels, sampwidth, framerate(采样率), nframes(# 帧数), comptype, compname\n",
        "            params = f.getparams()\n",
        "            # 解析各种音频数据\n",
        "            nchannels, sampwidth, framerate, nframes = params[:4]\n",
        "            # 读取并返回以 bytes 对象表示的最多 n 帧音频。\n",
        "            buffer_data = f.readframes(nframes)\n",
        "            # 把buffer数据格式化为short\n",
        "            wavedata = np.frombuffer(buffer_data, dtype=np.short)\n",
        "            # 每个点的序号乘以我们的采样率的倒数（就是采样一个点的时间）来计算获取每个时间帧以查的时间\n",
        "            time = np.arange(0, nframes) * (1.0 / framerate)\n",
        "            f.close()\n",
        "        return wavedata, time, framerate\n",
        "\n",
        "    # 读取IEMOCAP文件获取他的均值和方差\n",
        "    def read_IEMOCAP_and_get_std_mean(self):\n",
        "        train_num = 0\n",
        "        # 遍历数据集，一个数据集即一个session\n",
        "        for speaker in os.listdir(self.rootdir):\n",
        "            # 找个含有数据的数据文件夹\n",
        "            if (speaker[0] == 'S'):\n",
        "                # 找到该文件夹下的音频文件夹\n",
        "                sub_dir = os.path.join(self.rootdir, speaker, 'sentences/wav')\n",
        "                # 找到文件夹下的标注文件夹\n",
        "                emoevl = os.path.join(self.rootdir, speaker, 'dialog/EmoEvaluation')\n",
        "\n",
        "\n",
        "                # 开始遍历每个人名下的所有音频文件夹，这个音频文件下面有许多的音频文件，这些音频文件有一个专门的txt文件进行标注\n",
        "                for sess in os.listdir(sub_dir):\n",
        "                    # 寻找到字样为impro的文件作为训练文件\n",
        "                    if (sess[7] == 'i'):\n",
        "                        # 寻找标注文件记录每个音频文件的感情类别\n",
        "                        emotdir = emoevl + '/' + sess + '.txt'\n",
        "                        emot_map = {}\n",
        "                        with open(emotdir, 'r') as emot_to_read:\n",
        "                            while True:\n",
        "                                line = emot_to_read.readline()\n",
        "                                if not line:\n",
        "                                    break\n",
        "                                # 找到[开头的行\n",
        "                                if (line[0] == '['):\n",
        "                                    t = line.split()\n",
        "                                    # 采集每个音频对应的情感类别\n",
        "                                    emot_map[t[3]] = t[4]\n",
        "\n",
        "                        # 获取指定目录下的所有文档\n",
        "                        file_dir = os.path.join(sub_dir, sess, '*.wav')\n",
        "                        files = glob.glob(file_dir)\n",
        "                        # 遍历一个文件夹下的所有音频文件进行处理\n",
        "                        for filename in files:\n",
        "                            # 提取文件名\n",
        "                            wavname = filename.split(\"\\\\\")[-1][:-4]\n",
        "                            # 找到对应的感情标注\n",
        "                            emotion = emot_map[wavname]\n",
        "                            # 过滤出需要使用的四种感情对应的音频文件\n",
        "                            if (emotion in ['hap', 'ang', 'neu', 'sad']):\n",
        "                                #开始读取音频文件\n",
        "                                data, time, rate = self.read_file(filename)\n",
        "                                # 执行logfback函数来获取- Log Filterbank Energies\n",
        "                                # 参考这个地方的解释\n",
        "                                # https://cloud.tencent.com/edu/learning/course-2405-37616\n",
        "                                # 计算mel,detal,detal-detal特征\n",
        "                                # Filter banks和MFCC语音特征提取，整体是相似的，MFCC只是多了一步DCT（离散余弦变换）罢了\n",
        "                                # todo 改进这个地方没有使用真正的MFCC特征\n",
        "                                #####################################################################\n",
        "                                # 对每个滤波器的能量取log\n",
        "                                mel_spec = ps.logfbank(data, rate, nfilt=self.filter_num)\n",
        "                                #直接在log Mels上做一阶差分和二阶差分的\n",
        "                                delta1 = ps.delta(mel_spec, 2)\n",
        "                                delta2 = ps.delta(delta1, 2)\n",
        "                                #########################################################\n",
        "                                # 获取频谱图的时间长度\n",
        "                                time = mel_spec.shape[0]\n",
        "                                # 开始将获取到的特征数据保存到对应的特征层上\n",
        "                                if (speaker in ['Session1', 'Session2', 'Session3', 'Session4']):\n",
        "                                    # training set\n",
        "                                    # 把时间长度不够300的填补上0\n",
        "                                    if (time <= 300):\n",
        "                                        part = mel_spec\n",
        "                                        delta11 = delta1\n",
        "                                        delta21 = delta2\n",
        "                                        # ((1, 1), (2, 2))\n",
        "                                        # 表示在二维数组array第一维（此处便是行）前面填充1行，最后面填充1行；此处参考的位置为原来数组，前面就是指当前数组前面，后面是指当前数组后面\n",
        "                                        # 在二维数组array第二维（此处便是列）前面填充2列，最后面填充2列\n",
        "                                        # constant_values = (0, 3)\n",
        "                                        # 表示第一维填充0，第二维填充3\n",
        "                                        part = np.pad(part, ((0, 300 - part.shape[0]), (0, 0)), 'constant',\n",
        "                                                      constant_values=0)\n",
        "                                        delta11 = np.pad(delta11, ((0, 300 - delta11.shape[0]), (0, 0)), 'constant',\n",
        "                                                         constant_values=0)\n",
        "                                        delta21 = np.pad(delta21, ((0, 300 - delta21.shape[0]), (0, 0)), 'constant',\n",
        "                                                         constant_values=0)\n",
        "                                        # 填充特征矩阵\n",
        "                                        self.traindata1[train_num * 300:(train_num + 1) * 300] = part\n",
        "                                        self.traindata2[train_num * 300:(train_num + 1) * 300] = delta11\n",
        "                                        self.traindata3[train_num * 300:(train_num + 1) * 300] = delta21\n",
        "                                        # 统计训练样本数目\n",
        "                                        # 更新下一个数据插入的位置\n",
        "                                        train_num = train_num + 1\n",
        "                                    # 把多余300长度的数据进行截取\n",
        "                                    else:\n",
        "                                        if (emotion in ['ang', 'neu', 'sad']):\n",
        "                                            # todo 改进，可以和开心数据提取一样来多提取数据\n",
        "                                            # 取了音频数据的前300个时间帧和后300个时间帧\n",
        "                                            for i in range(2):\n",
        "                                                if (i == 0):\n",
        "                                                    begin = 0\n",
        "                                                    end = begin + 300\n",
        "                                                else:\n",
        "                                                    begin = time - 300\n",
        "                                                    end = time\n",
        "\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.traindata1[train_num * 300:(train_num + 1) * 300] = part\n",
        "                                                self.traindata2[train_num * 300:(train_num + 1) * 300] = delta11\n",
        "                                                self.traindata3[train_num * 300:(train_num + 1) * 300] = delta21\n",
        "                                                # todo 更新下一个数据插入的位置\n",
        "                                                train_num = train_num + 1\n",
        "                                        # 对开心分类的数据进行更多的数据提取，因为他的数据相对较少。所以以100帧为间隔反复提取\n",
        "                                        else:\n",
        "                                            frames = divmod(time - 300, 100)[0]\n",
        "                                            # 加1保证循环范围为0——frames\n",
        "                                            for i in range(frames+1):\n",
        "                                                begin = 100 * i\n",
        "                                                end = begin + 300\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.traindata1[train_num * 300:(train_num + 1) * 300] = part\n",
        "                                                self.traindata2[train_num * 300:(train_num + 1) * 300] = delta11\n",
        "                                                self.traindata3[train_num * 300:(train_num + 1) * 300] = delta21\n",
        "                                                # todo 更新下一个数据插入的位置\n",
        "                                                train_num = train_num + 1\n",
        "                                else:\n",
        "                                    # 可以继续往下执行\n",
        "                                    pass\n",
        "                            else:\n",
        "                                # 可以继续往下执行\n",
        "                                pass\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            # todo 求每一个session三个特征数据的均值和标准差，并保存\n",
        "            self.mean1 = np.mean(self.traindata1, axis=0)  # axis=0纵轴方向求均值\n",
        "            self.std1 = np.std(self.traindata1, axis=0)\n",
        "            self.mean2 = np.mean(self.traindata2, axis=0)  # axis=0纵轴方向求均值\n",
        "            self.std2 = np.std(self.traindata2, axis=0)\n",
        "            self.mean3 = np.mean(self.traindata3, axis=0)  # axis=0纵轴方向求均值\n",
        "            self.std3 = np.std(self.traindata3, axis=0)\n",
        "            # output = './zscore' + str(self.filter_num) + '.pkl'\n",
        "            # f = open(output, 'wb')\n",
        "            # cPickle.dump((mean1, std1, mean2, std2, mean3, std3), f)\n",
        "            # f.close()\n",
        "        return\n",
        "\n",
        "    def generate_label(self,emotion):\n",
        "        label = -1\n",
        "        if (emotion == 'ang'):\n",
        "            label = 0\n",
        "        elif (emotion == 'sad'):\n",
        "            label = 1\n",
        "        elif (emotion == 'hap'):\n",
        "            label = 2\n",
        "        elif (emotion == 'neu'):\n",
        "            label = 3\n",
        "        elif (emotion == 'fear'):\n",
        "            label = 4\n",
        "        else:\n",
        "            label = 5\n",
        "        return label\n",
        "\n",
        "    def load_data(self):\n",
        "        f = open('./zscore40.pkl', 'rb')\n",
        "        mean1, std1, mean2, std2, mean3, std3 = cPickle.load(f)\n",
        "        return mean1, std1, mean2, std2, mean3, std3\n",
        "\n",
        "    def read_IEMOCAP(self):\n",
        "        tnum = 0\n",
        "        vnum = 0\n",
        "        train_num = 0\n",
        "        test_num = 0\n",
        "        valid_num = 0\n",
        "        # 遍历数据集，一个数据集即一个session\n",
        "        for speaker in os.listdir( self.rootdir):\n",
        "            if (speaker[0] == 'S'):\n",
        "                # 找到该文件夹下的音频文件夹\n",
        "                sub_dir = os.path.join( self.rootdir, speaker, 'sentences/wav')\n",
        "                # 找到文件夹下的标注文件夹\n",
        "                emoevl = os.path.join( self.rootdir, speaker, 'dialog/EmoEvaluation')\n",
        "                # 开始遍历每个人名下的所有音频文件夹，这个音频文件下面有许多的音频文件，这些音频文件有一个专门的txt文件进行标注\n",
        "                for sess in os.listdir(sub_dir):\n",
        "                    # 寻找到字样为impro的文件作为训练文件\n",
        "                    if (sess[7] == 'i'):\n",
        "                        # 寻找标注文件记录每个音频文件的感情类别\n",
        "                        emotdir = emoevl + '/' + sess + '.txt'\n",
        "                        emot_map = {}\n",
        "                        with open(emotdir, 'r') as emot_to_read:\n",
        "                            while True:\n",
        "                                line = emot_to_read.readline()\n",
        "                                if not line:\n",
        "                                    break\n",
        "                                # 找到[开头的行\n",
        "                                if (line[0] == '['):\n",
        "                                    t = line.split()\n",
        "                                    # 采集每个音频对应的情感类别\n",
        "                                    emot_map[t[3]] = t[4]\n",
        "                        # 获取指定目录下的所有文档\n",
        "                        file_dir = os.path.join(sub_dir, sess, '*.wav')\n",
        "                        files = glob.glob(file_dir)\n",
        "                        # 遍历一个文件夹下的所有音频文件进行处理\n",
        "                        for filename in files:\n",
        "                            # 对一个音频进出处理\n",
        "                            wavname = filename.split(\"\\\\\")[-1][:-4]\n",
        "                            # 找到对应的感情标注\n",
        "                            emotion = emot_map[wavname]\n",
        "                            # 过滤出需要使用的四种感情对应的音频文件\n",
        "                            if (emotion in ['hap', 'ang', 'neu', 'sad']):\n",
        "                                # 开始读取音频文件\n",
        "                                data, time, rate =  self.read_file(filename)\n",
        "                                # 计算mel , delta1,dalta2数据\n",
        "                                mel_spec = ps.logfbank(data, rate, nfilt= self.filter_num)\n",
        "                                delta1 = ps.delta(mel_spec, 2)\n",
        "                                delta2 = ps.delta(delta1, 2)\n",
        "                                time = mel_spec.shape[0]\n",
        "                                # 1-4是训练集合，进行训练集合的处理\n",
        "                                if (speaker in ['Session1', 'Session2', 'Session3', 'Session4']):\n",
        "                                    # training set\n",
        "                                    # 把时间长度不够300的填补上0\n",
        "                                    if (time <= 300):\n",
        "                                        part = mel_spec\n",
        "                                        delta11 = delta1\n",
        "                                        delta21 = delta2\n",
        "                                        part = np.pad(part, ((0, 300 - part.shape[0]), (0, 0)), 'constant',\n",
        "                                                      constant_values=0)\n",
        "                                        delta11 = np.pad(delta11, ((0, 300 - delta11.shape[0]), (0, 0)), 'constant',\n",
        "                                                         constant_values=0)\n",
        "                                        delta21 = np.pad(delta21, ((0, 300 - delta21.shape[0]), (0, 0)), 'constant',\n",
        "                                                         constant_values=0)\n",
        "                                        # train_data有四个维度分别为batch,帧长，特征数目，层数\n",
        "                                        # 依次循环将三种特征放入不同的层数，并且每个特征就计算了Z-score来进行归一化的处理\n",
        "                                        self.train_data[train_num, :, :, 0] = (part - self.mean1) / (self.std1 + self.eps)\n",
        "                                        self.train_data[train_num, :, :, 1] = (delta11 - self.mean2) / (self.std2 + self.eps)\n",
        "                                        self.train_data[train_num, :, :, 2] = (delta21 - self.mean3) / (self.std3 + self.eps)\n",
        "                                        # 生成一个感情表示的序号\n",
        "                                        em = self.generate_label(emotion)\n",
        "                                        # 记录该batch对应的感情类别序号——记录一个图片对应的标签值\n",
        "                                        self.train_label[train_num] = em\n",
        "                                        # 统计记录一下各个感情类别的数目\n",
        "                                        self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "                                        # 更新batch序号\n",
        "                                        train_num = train_num + 1\n",
        "                                    else:\n",
        "\n",
        "                                        if (emotion in ['ang', 'neu', 'sad']):\n",
        "                                            # 取前300帧和后300帧来作为训练样本\n",
        "                                            for i in range(2):\n",
        "                                                if (i == 0):\n",
        "                                                    begin = 0\n",
        "                                                    end = begin + 300\n",
        "                                                else:\n",
        "                                                    begin = time - 300\n",
        "                                                    end = time\n",
        "\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.train_data[train_num, :, :, 0] = (part - self.mean1) / (self.std1 + self.eps)\n",
        "                                                self.train_data[train_num, :, :, 1] = (delta11 - self.mean2) / (self.std2 + self.eps)\n",
        "                                                self.train_data[train_num, :, :, 2] = (delta21 - self.mean3) / (self.std3 + self.eps)\n",
        "\n",
        "                                                em = self.generate_label(emotion)\n",
        "                                                self.train_label[train_num] = em\n",
        "                                                self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "                                                train_num = train_num + 1\n",
        "                                        else:\n",
        "                                            # 每隔100帧取一个样本\n",
        "                                            frames = divmod(time - 300, 100)[0] + 1\n",
        "                                            for i in range(frames):\n",
        "                                                begin = 100 * i\n",
        "                                                end = begin + 300\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.train_data[train_num, :, :, 0] = (part - self.mean1) / (self.std1 + self.eps)\n",
        "                                                self.train_data[train_num, :, :, 1] = (delta11 - self.mean2) / (self.std2 + self.eps)\n",
        "                                                self.train_data[train_num, :, :, 2] = (delta21 - self.mean3) / (self.std3 + self.eps)\n",
        "                                                em = self.generate_label(emotion)\n",
        "                                                self.train_label[train_num] = em\n",
        "                                                self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "                                                train_num = train_num + 1\n",
        "                                # 5是测试集进出测试集验证集合的处理\n",
        "                                else:\n",
        "                                    # 生成当前音频的感情标签\n",
        "                                    em = self.generate_label(emotion)\n",
        "                                    # 生成测试集的数据样本\n",
        "                                    if (wavname[-4] == 'M'):\n",
        "                                        # todo test_set\n",
        "                                        self.test_label[tnum] = em\n",
        "                                        if (time <= 300):\n",
        "                                            self.pernums_test[tnum] = 1\n",
        "                                            part = mel_spec\n",
        "                                            delta11 = delta1\n",
        "                                            delta21 = delta2\n",
        "                                            part = np.pad(part, ((0, 300 - part.shape[0]), (0, 0)), 'constant',\n",
        "                                                          constant_values=0)\n",
        "                                            delta11 = np.pad(delta11, ((0, 300 - delta11.shape[0]), (0, 0)), 'constant',\n",
        "                                                             constant_values=0)\n",
        "                                            delta21 = np.pad(delta21, ((0, 300 - delta21.shape[0]), (0, 0)), 'constant',\n",
        "                                                             constant_values=0)\n",
        "                                            self.test_data[test_num, :, :, 0] = (part - self.mean1) / (self.std1 + self.eps)\n",
        "                                            self.test_data[test_num, :, :, 1] = (delta11 - self.mean2) / (self.std2 +self.eps)\n",
        "                                            self.test_data[test_num, :, :, 2] = (delta21 - self.mean3) / (self.std3 + self.eps)\n",
        "\n",
        "                                            self.test_emt[emotion] = self.test_emt[emotion] + 1\n",
        "                                            self.Test_label[test_num] = em\n",
        "                                            test_num = test_num + 1\n",
        "                                            tnum = tnum + 1\n",
        "\n",
        "                                        else:\n",
        "                                            self.pernums_test[tnum] = 2\n",
        "                                            tnum = tnum + 1\n",
        "                                            for i in range(2):\n",
        "                                                if (i == 0):\n",
        "                                                    begin = 0\n",
        "                                                    end = begin + 300\n",
        "                                                else:\n",
        "                                                    end = time\n",
        "                                                    begin = time - 300\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.test_data[test_num, :, :, 0] = (part - self.mean1) / (self.std1 + self.eps)\n",
        "                                                self.test_data[test_num, :, :, 1] = (delta11 - self.mean2) / (self.std2 + self.eps)\n",
        "                                                self.test_data[test_num, :, :, 2] = (delta21 - self.mean3) / (self.std3 + self.eps)\n",
        "\n",
        "                                                self.test_emt[emotion] = self.test_emt[emotion] + 1\n",
        "                                                self.Test_label[test_num] = em\n",
        "                                                test_num = test_num + 1\n",
        "\n",
        "                                    else:\n",
        "                                        # todo valid_set\n",
        "                                        em = self.generate_label(emotion)\n",
        "                                        self.valid_label[vnum] = em\n",
        "                                        if (time <= 300):\n",
        "                                            self.pernums_valid[vnum] = 1\n",
        "                                            part = mel_spec\n",
        "                                            delta11 = delta1\n",
        "                                            delta21 = delta2\n",
        "                                            part = np.pad(part, ((0, 300 - part.shape[0]), (0, 0)), 'constant',\n",
        "                                                          constant_values=0)\n",
        "                                            delta11 = np.pad(delta11, ((0, 300 - delta11.shape[0]), (0, 0)), 'constant',\n",
        "                                                             constant_values=0)\n",
        "                                            delta21 = np.pad(delta21, ((0, 300 - delta21.shape[0]), (0, 0)), 'constant',\n",
        "                                                             constant_values=0)\n",
        "                                            self.valid_data[valid_num, :, :, 0] = (part - self.mean1) / (self.std1 + self.eps)\n",
        "                                            self.valid_data[valid_num, :, :, 1] = (delta11 - self.mean2) / (self.std2 + self.eps)\n",
        "                                            self.valid_data[valid_num, :, :, 2] = (delta21 - self.mean3) / (self.std3 + self.eps)\n",
        "                                            self.valid_emt[emotion] = self.valid_emt[emotion] + 1\n",
        "                                            self.Valid_label[valid_num] = em\n",
        "                                            valid_num = valid_num + 1\n",
        "                                            vnum = vnum + 1\n",
        "                                        else:\n",
        "                                            self.pernums_valid[vnum] = 2\n",
        "                                            vnum = vnum + 1\n",
        "                                            for i in range(2):\n",
        "                                                if (i == 0):\n",
        "                                                    begin = 0\n",
        "                                                    end = begin + 300\n",
        "                                                else:\n",
        "                                                    end = time\n",
        "                                                    begin = time - 300\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.valid_data[valid_num, :, :, 0] = (part - self.mean1) / (self.std1 +self. eps)\n",
        "                                                self.valid_data[valid_num, :, :, 1] = (delta11 - self.mean2) / (self.std2 + self.eps)\n",
        "                                                self.valid_data[valid_num, :, :, 2] = (delta21 - self.mean3) / (self.std3 + self.eps)\n",
        "                                                self.valid_emt[emotion] = self.valid_emt[emotion] + 1\n",
        "                                                self.Valid_label[valid_num] = em\n",
        "                                                valid_num = valid_num + 1\n",
        "\n",
        "                            else:\n",
        "                                pass\n",
        "\n",
        "        # 生成各种数据集的序号\n",
        "        hap_index = np.arange(self.hapnum)\n",
        "        neu_index = np.arange(self.neunum)\n",
        "        sad_index = np.arange(self.sadnum)\n",
        "        ang_index = np.arange(self.angnum)\n",
        "        h2 = 0\n",
        "        a0 = 0\n",
        "        n3 = 0\n",
        "        s1 = 0\n",
        "        # 把训练的集合的序号按类别来分配到对应的类别数组，每个数组记录了对应的类别在train_label里的位置\n",
        "        for l in range(train_num):\n",
        "            if (self.train_label[l] == 0):\n",
        "                ang_index[a0] = l\n",
        "                a0 = a0 + 1\n",
        "            elif (self.train_label[l] == 1):\n",
        "                sad_index[s1] = l\n",
        "                s1 = s1 + 1\n",
        "            elif (self.train_label[l] == 2):\n",
        "                hap_index[h2] = l\n",
        "                h2 = h2 + 1\n",
        "            else:\n",
        "                neu_index[n3] = l\n",
        "                n3 = n3 + 1\n",
        "        # todo 构建数据集\n",
        "        for m in range(1):\n",
        "            # todo 打乱数据内部的数据排列顺序\n",
        "            np.random.shuffle(neu_index)\n",
        "            np.random.shuffle(hap_index)\n",
        "            np.random.shuffle(sad_index)\n",
        "            np.random.shuffle(ang_index)\n",
        "            # define emotional array\n",
        "            # todo pernum表示的是一个batch的大小\n",
        "            hap_label = np.empty((self.pernum, 1), dtype=np.int8)\n",
        "            ang_label = np.empty((self.pernum, 1), dtype=np.int8)\n",
        "            sad_label = np.empty((self.pernum, 1), dtype=np.int8)\n",
        "            neu_label = np.empty((self.pernum, 1), dtype=np.int8)\n",
        "            hap_data = np.empty((self.pernum, 300, self.filter_num, 3), dtype=np.float32)\n",
        "            neu_data = np.empty((self.pernum, 300, self.filter_num, 3), dtype=np.float32)\n",
        "            sad_data = np.empty((self.pernum, 300, self.filter_num, 3), dtype=np.float32)\n",
        "            ang_data = np.empty((self.pernum, 300, self.filter_num, 3), dtype=np.float32)\n",
        "            # todo 再各个类别的图片里选取300个样本\n",
        "            hap_data = self.train_data[hap_index[0:self.pernum]].copy()\n",
        "            hap_label = self.train_label[hap_index[0:self.pernum]].copy()\n",
        "            ang_data = self.train_data[ang_index[0:self.pernum]].copy()\n",
        "            ang_label = self.train_label[ang_index[0:self.pernum]].copy()\n",
        "            sad_data = self.train_data[sad_index[0:self.pernum]].copy()\n",
        "            sad_label = self.train_label[sad_index[0:self.pernum]].copy()\n",
        "            neu_data = self.train_data[neu_index[0:self.pernum]].copy()\n",
        "            neu_label = self.train_label[neu_index[0:self.pernum]].copy()\n",
        "            # todo 统计下要使用的数据集个数 4*300\n",
        "            train_num = 4 * self.pernum\n",
        "            # todo 来把不同的数据集来合并起来\n",
        "            Train_label = np.empty((train_num, 1), dtype=np.int8)\n",
        "            Train_data = np.empty((train_num, 300, self.filter_num, 3), dtype=np.float32)\n",
        "            Train_data[0:self.pernum] = hap_data\n",
        "            Train_label[0:self.pernum] = hap_label\n",
        "            Train_data[self.pernum:2 * self.pernum] = sad_data\n",
        "            Train_label[self.pernum:2 * self.pernum] = sad_label\n",
        "            Train_data[2 * self.pernum:3 * self.pernum] = neu_data\n",
        "            Train_label[2 * self.pernum:3 * self.pernum] = neu_label\n",
        "            Train_data[3 * self.pernum:4 * self.pernum] = ang_data\n",
        "            Train_label[3 * self.pernum:4 * self.pernum] = ang_label\n",
        "            # todo 重新打乱一些\n",
        "            arr = np.arange(train_num)\n",
        "            np.random.shuffle(arr)\n",
        "            Train_data = Train_data[arr[0:]]\n",
        "            Train_label = Train_label[arr[0:]]\n",
        "\n",
        "            output = './IEMOCAP.pkl'\n",
        "            f = open(output, 'wb')\n",
        "            # todo 记录一个batch\n",
        "            cPickle.dump((Train_data, Train_label, self.test_data, self.test_label, self.valid_data, self.valid_label, self.Valid_label, self.Test_label, self.pernums_test, self.pernums_valid), f)\n",
        "            f.close()\n",
        "        return Train_data, Train_label\n",
        "\n",
        "\n",
        "    # 获取到采集样本的数量\n",
        "    def get_numof_sample(self):\n",
        "        train_num = 0\n",
        "        print(self.rootdir)\n",
        "        for speaker in os.listdir(self.rootdir):\n",
        "            if (speaker[0] == 'S'):\n",
        "                sub_dir = os.path.join(self.rootdir, speaker, 'sentences/wav')\n",
        "                emoevl = os.path.join(self.rootdir, speaker, 'dialog/EmoEvaluation')\n",
        "                for sess in os.listdir(sub_dir):\n",
        "                    if (sess[7] == 'i'):\n",
        "                        emotdir = emoevl + '/' + sess + '.txt'\n",
        "                        emot_map = {}\n",
        "                        with open(emotdir, 'r') as emot_to_read:\n",
        "                            while True:\n",
        "                                line = emot_to_read.readline()\n",
        "                                if not line:\n",
        "                                    break\n",
        "                                if (line[0] == '['):\n",
        "                                    t = line.split()\n",
        "                                    emot_map[t[3]] = t[4]\n",
        "                        file_dir = os.path.join(sub_dir, sess, '*.wav')\n",
        "                        files = glob.glob(file_dir)\n",
        "                        for filename in files:\n",
        "                            wavname = filename.split(\"/\")[-1][:-4]\n",
        "                            if \"(\" in wavname:\n",
        "                              continue\n",
        "                            emotion = emot_map[wavname]\n",
        "                            if (emotion in ['hap', 'ang', 'neu', 'sad']):\n",
        "                                # 开始读取音频文件\n",
        "                                data, time, rate = self.read_file(filename)\n",
        "                                mel_spec = ps.logfbank(data, rate, nfilt=self.filter_num)\n",
        "                                time = mel_spec.shape[0]\n",
        "                                if (speaker in ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']):\n",
        "                                    if (time <= 300):\n",
        "                                        train_num = train_num + 1\n",
        "\n",
        "                                    else:\n",
        "                                        if (emotion in ['ang', 'neu', 'sad']):\n",
        "                                            for i in range(2):\n",
        "                                                train_num = train_num + 1\n",
        "                                        else:\n",
        "                                            frames = divmod(time - 300, 100)[0]\n",
        "                                            for i in range(frames + 1):\n",
        "                                                # todo 更新下一个数据插入的位置\n",
        "                                                train_num = train_num + 1\n",
        "        return train_num\n",
        "    # 获取样本和标签\n",
        "    def get_sample_and_lable(self):\n",
        "        train_num = 0\n",
        "        for speaker in os.listdir(self.rootdir):\n",
        "            if (speaker[0] == 'S'):\n",
        "                # 找到该文件夹下的音频文件夹\n",
        "                sub_dir = os.path.join(self.rootdir, speaker, 'sentences/wav')\n",
        "                # 找到文件夹下的标注文件夹\n",
        "                emoevl = os.path.join(self.rootdir, speaker, 'dialog/EmoEvaluation')\n",
        "                # 开始遍历每个人名下的所有音频文件夹，这个音频文件下面有许多的音频文件，这些音频文件有一个专门的txt文件进行标注\n",
        "                for sess in os.listdir(sub_dir):\n",
        "                    # 寻找到字样为impro的文件作为训练文件\n",
        "                    if (sess[7] == 'i'):\n",
        "                        # 寻找标注文件记录每个音频文件的感情类别\n",
        "                        emotdir = emoevl + '/' + sess + '.txt'\n",
        "                        emot_map = {}\n",
        "                        with open(emotdir, 'r') as emot_to_read:\n",
        "                            while True:\n",
        "                                line = emot_to_read.readline()\n",
        "                                if not line:\n",
        "                                    break\n",
        "                                # 找到[开头的行\n",
        "                                if (line[0] == '['):\n",
        "                                    t = line.split()\n",
        "                                    # 采集每个音频对应的情感类别\n",
        "                                    emot_map[t[3]] = t[4]\n",
        "                        # 获取指定目录下的所有文档\n",
        "                        file_dir = os.path.join(sub_dir, sess, '*.wav')\n",
        "                        files = glob.glob(file_dir)\n",
        "                        # 遍历一个文件夹下的所有音频文件进行处理\n",
        "                        for filename in files:\n",
        "                            # 对一个音频进出处理\n",
        "                            wavname = filename.split(\"/\")[-1][:-4]\n",
        "                            if \"(\" in wavname:\n",
        "                              continue\n",
        "                            # 找到对应的感情标注\n",
        "                            emotion = emot_map[wavname]\n",
        "                            # 过滤出需要使用的四种感情对应的音频文件\n",
        "                            if (emotion in ['hap', 'ang', 'neu', 'sad']):\n",
        "                                # 开始读取音频文件\n",
        "                                data, time, rate = self.read_file(filename)\n",
        "                                # 计算mel , delta1,dalta2数据\n",
        "                                mel_spec = ps.logfbank(data, rate, nfilt=self.filter_num)\n",
        "                                delta1 = ps.delta(mel_spec, 2)\n",
        "                                delta2 = ps.delta(delta1, 2)\n",
        "                                time = mel_spec.shape[0]\n",
        "                                # 1-4是训练集合，进行训练集合的处理\n",
        "                                if (speaker in ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']):\n",
        "                                    # training set\n",
        "                                    # 把时间长度不够300的填补上0\n",
        "                                    if (time <= 300):\n",
        "                                        part = mel_spec\n",
        "                                        delta11 = delta1\n",
        "                                        delta21 = delta2\n",
        "                                        part = np.pad(part, ((0, 300 - part.shape[0]), (0, 0)), 'constant',\n",
        "                                                      constant_values=0)\n",
        "                                        delta11 = np.pad(delta11, ((0, 300 - delta11.shape[0]), (0, 0)), 'constant',\n",
        "                                                         constant_values=0)\n",
        "                                        delta21 = np.pad(delta21, ((0, 300 - delta21.shape[0]), (0, 0)), 'constant',\n",
        "                                                         constant_values=0)\n",
        "                                        # train_data有四个维度分别为batch,帧长，特征数目，层数\n",
        "                                        # 依次循环将三种特征放入不同的层数，并且每个特征就计算了Z-score来进行归一化的处理\n",
        "                                        self.traindata1[train_num * 300:(train_num + 1) * 300] = part\n",
        "                                        self.traindata2[train_num * 300:(train_num + 1) * 300] = delta11\n",
        "                                        self.traindata3[train_num * 300:(train_num + 1) * 300] = delta21\n",
        "                                        # 生成一个感情表示的序号\n",
        "                                        em = self.generate_label(emotion)\n",
        "                                        # 记录该batch对应的感情类别序号——记录一个图片对应的标签值\n",
        "                                        self.train_label[train_num] = em\n",
        "                                        # 统计记录一下各个感情类别的数目\n",
        "                                        self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "                                        # 更新batch序号\n",
        "                                        train_num = train_num + 1\n",
        "                                    else:\n",
        "\n",
        "                                        if (emotion in ['ang', 'neu', 'sad']):\n",
        "                                            # 取前300帧和后300帧来作为训练样本\n",
        "                                            for i in range(2):\n",
        "                                                if (i == 0):\n",
        "                                                    begin = 0\n",
        "                                                    end = begin + 300\n",
        "                                                else:\n",
        "                                                    begin = time - 300\n",
        "                                                    end = time\n",
        "\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.traindata1[train_num * 300:(train_num + 1) * 300] = part\n",
        "                                                self.traindata2[train_num * 300:(train_num + 1) * 300] = delta11\n",
        "                                                self.traindata3[train_num * 300:(train_num + 1) * 300] = delta21\n",
        "\n",
        "                                                em = self.generate_label(emotion)\n",
        "                                                self.train_label[train_num] = em\n",
        "                                                self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "                                                train_num = train_num + 1\n",
        "                                        else:\n",
        "                                            # 每隔100帧取一个样本\n",
        "                                            frames = divmod(time - 300, 100)[0] + 1\n",
        "                                            for i in range(frames):\n",
        "                                                begin = 100 * i\n",
        "                                                end = begin + 300\n",
        "                                                part = mel_spec[begin:end, :]\n",
        "                                                delta11 = delta1[begin:end, :]\n",
        "                                                delta21 = delta2[begin:end, :]\n",
        "                                                self.traindata1[train_num * 300:(train_num + 1) * 300] = part\n",
        "                                                self.traindata2[train_num * 300:(train_num + 1) * 300] = delta11\n",
        "                                                self.traindata3[train_num * 300:(train_num + 1) * 300] = delta21\n",
        "                                                em = self.generate_label(emotion)\n",
        "                                                self.train_label[train_num] = em\n",
        "                                                self.train_emt[emotion] = self.train_emt[emotion] + 1\n",
        "                                                train_num = train_num + 1\n",
        "            # # todo 求每一个session三个特征数据的均值和标准差，并保存\n",
        "            # self.mean1 = np.mean(self.traindata1, axis=0)  # axis=0纵轴方向求均值\n",
        "            # self.std1 = np.std(self.traindata1, axis=0)\n",
        "            # self.mean2 = np.mean(self.traindata2, axis=0)  # axis=0纵轴方向求均值\n",
        "            # self.std2 = np.std(self.traindata2, axis=0)\n",
        "            # self.mean3 = np.mean(self.traindata3, axis=0)  # axis=0纵轴方向求均值\n",
        "            # self.std3 = np.std(self.traindata3, axis=0)\n",
        "            # # output = './zscore' + str(self.filter_num) + '.pkl'\n",
        "            # # f = open(output, 'wb')\n",
        "            # # cPickle.dump((mean1, std1, mean2, std2, mean3, std3), f)\n",
        "            # # f.close()\n",
        "\n",
        "    def normalization(self,data):\n",
        "        '''\n",
        "        #apply zscore\n",
        "        mean = np.mean(data,axis=0)#axis=0纵轴方向求均值\n",
        "        std = np.std(data,axis=0)\n",
        "        train_data = zscore(train_data,mean,std)\n",
        "        test_data = zscore(test_data,mean,std)\n",
        "        '''\n",
        "        mean = np.mean(data, axis=0)  # axis=0纵轴方向求均值\n",
        "        std = np.std(data, axis=0)\n",
        "        data = (data - mean) / std\n",
        "        return data\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        print(\"开始获取样本和标签值\")\n",
        "        self.get_sample_and_lable()\n",
        "        # 获取数据集合的所有样本声谱图数据和对应的标签数据——sample，lable\n",
        "        ## 1.获取到一维的标签列表，将他转化为dataset的数据类型\n",
        "        tf_label = self.train_label.T.squeeze()\n",
        "        label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(tf_label,tf.int64))\n",
        "        ## 2.获取到数据样本\n",
        "        ### 2.1. 对三个特征层进行标准化处理\n",
        "        self.traindata1 = self.normalization(self.traindata1)\n",
        "        self.traindata2 = self.normalization(self.traindata2)\n",
        "        self.traindata3 = self.normalization(self.traindata3)\n",
        "        ### 2.2. 将三个特征层合并 格式化为[in_height, in_width, in_channels]——[40,300,3]\n",
        "        self.traindata1 = tf.reshape(self.traindata1,[-1,300,40])\n",
        "        self.traindata2 = tf.reshape(self.traindata2,[-1,300,40])\n",
        "        self.traindata3 = tf.reshape(self.traindata3,[-1,300,40])\n",
        "        concat_all = tf.transpose(tf.stack([self.traindata1,self.traindata2,self.traindata3],3), perm=[0, 2, 1,3])\n",
        "        sampledata = tf.data.Dataset.from_tensor_slices(concat_all)\n",
        "        ## 3把两个dataset合并构成一个dataset\n",
        "        ds = tf.data.Dataset.zip((sampledata, label_ds))\n",
        "        ## 4.划分训练集和验证集合\n",
        "        train_data = ds.skip(int(self.train_nums*0.2)).shuffle(int(self.train_nums-self.train_nums*0.2)).batch(32,drop_remainder=True)\n",
        "        val_data = ds.take(int(self.train_nums*0.2)).shuffle(int(self.train_nums-self.train_nums*0.2)).batch(32,drop_remainder=True)\n",
        "        print(\"训练样本数量\")\n",
        "        print(self.train_nums)\n",
        "        return train_data,val_data\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r84noU8D6ICD"
      },
      "source": [
        "a = mydataset_IEMOCAP_FOUR()\n",
        "traindata,valdata = a()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkUqeiJmy1_j"
      },
      "source": [
        "'''\n",
        "使用keras来构建我们的模型\n",
        "'''\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # 隐藏层的形状 == （批大小，隐藏层大小）\n",
        "    # hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）\n",
        "    # 这样做是为了执行加法以计算分数\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # 分数的形状 == （批大小，最大长度，1）\n",
        "    # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
        "    # 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self,batch_size,isbias=True):\n",
        "    super(MyModel, self,).__init__()\n",
        "    # 数据的batch大小\n",
        "    self.batch_size = batch_size\n",
        "    # 进行卷积操作\n",
        "    # layer1\n",
        "    self.conv1 = layers.Conv2D(filters=128, kernel_size=(5, 3), strides=1, padding='same', use_bias=isbias)  # 2d卷积\n",
        "    # self.bn1 = layers.BatchNormalization()\n",
        "    self.relu1 = layers.LeakyReLU()\n",
        "    # layer2\n",
        "    self.conv2 = layers.Conv2D(filters=256, kernel_size=(5, 3), strides=1, padding='same', use_bias=isbias)  # 2d卷积\n",
        "    # self.bn2 = layers.BatchNormalization()\n",
        "    self.relu2 = layers.LeakyReLU()\n",
        "    # layer3\n",
        "    self.conv3 = layers.Conv2D(filters=256, kernel_size=(5, 3), strides=1, padding='same', use_bias=isbias)  # 2d卷积\n",
        "    # self.bn3 = layers.BatchNormalization()\n",
        "    self.relu3 = layers.LeakyReLU()\n",
        "    # layer4\n",
        "    self.conv4 = layers.Conv2D(filters=256, kernel_size=(5, 3), strides=1, padding='same', use_bias=isbias)  # 2d卷积\n",
        "    # self.bn4 = layers.BatchNormalization()\n",
        "    self.relu4 = layers.LeakyReLU()\n",
        "    # layer5\n",
        "    self.conv5 = layers.Conv2D(filters=256, kernel_size=(5, 3), strides=1, padding='same', use_bias=isbias)  # 2d卷积\n",
        "    # self.bn5 = layers.BatchNormalization()\n",
        "    self.relu5 = layers.LeakyReLU()\n",
        "    # layer6\n",
        "    self.conv6 = layers.Conv2D(filters=256, kernel_size=(5, 3), strides=1, padding='same', use_bias=isbias)  # 2d卷积\n",
        "    # self.bn6 = layers.BatchNormalization()\n",
        "    self.relu6 = layers.LeakyReLU()\n",
        "    # 进行全连接操作，对数据进行降维\n",
        "    # layer7\n",
        "    self.Dense7 = layers.Dense(768)\n",
        "    self.relu7 = layers.LeakyReLU()\n",
        "    # 对卷积提取的特征进行RNN\n",
        "    # layer8\n",
        "    self.RNN8 = layers.Bidirectional(layers.GRU(128, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform'))\n",
        "    # 使用一个注意力层\n",
        "    # layer9\n",
        "    self.attention9 = BahdanauAttention(4)\n",
        "    # 使用全连接层\n",
        "    # layer10\n",
        "    self.Dense10 = layers.Dense(64)\n",
        "    self.relu10 = layers.LeakyReLU()\n",
        "    # 使用全连接层\n",
        "    # layer11\n",
        "    self.Dense11 = layers.Dense(4)\n",
        "\n",
        "  def call(self, x):\n",
        "    # 使用CNN进行特征提取\n",
        "    x = self.conv1(x)\n",
        "    # x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    # x = self.bn2(x)\n",
        "    x = self.relu2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    # x = self.bn3(x)\n",
        "    x = self.relu3(x)\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    # x = self.bn4(x)\n",
        "    x = self.relu4(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    # x = self.bn5(x)\n",
        "    x = self.relu5(x)\n",
        "\n",
        "    x = self.conv6(x)\n",
        "    # x = self.bn6(x)\n",
        "    x = self.relu6(x)\n",
        "    # 卷积后输出的矩阵大小为（batch_size，40，300，256）\n",
        "\n",
        "    # 进行展平处理\n",
        "    x = tf.reshape(x, [self.batch_size,-1, 150, 2560])\n",
        "    x = tf.reshape(x, [self.batch_size,-1, 2560])\n",
        "\n",
        "    # 经过全连接层进行降维\n",
        "    x = self.Dense7(x)\n",
        "    x = self.relu7(x)\n",
        "    # 使用RNN进行关系特征提取\n",
        "    x = self.RNN8(x)\n",
        "    # 进行注意力特征提取\n",
        "    x = self.attention9((x[1]+x[2])/2,x[0])[0]\n",
        "\n",
        "    # 进行全连接输出预测值\n",
        "    x = self.Dense10(x)\n",
        "    x = self.relu10(x)\n",
        "    x = self.Dense11(x)\n",
        "    return  x\n",
        "\n",
        "# model = MyModel(4)\n",
        "# temp_input = tf.random.uniform((4,40,300,3))\n",
        "# y= model(temp_input)\n",
        "# # with tf.GradientTape() as tape:\n",
        "# #   logits = model(images)\n",
        "# #   loss_value = loss(logits, labels)\n",
        "# # grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "# # optimizer.apply_gradients(zip(grads, model.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wYKmp91n5Lu"
      },
      "source": [
        "# 为训练选择优化器与损失函数：\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 选择衡量指标来度量模型的损失值（loss）和准确率（accuracy）。这些指标在epoch上累积值，然后打印出整体结果。\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "# 初始化我们的数据集和模型\n",
        "model = MyModel(16)\n",
        "train_ds, test_ds = traindata,valdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hESn8nb1akd8"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels, model):\n",
        "  with tf.GradientTape() as tape:\n",
        "      predictions = model(images)\n",
        "      loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels, model):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_teALzKF9vQ9"
      },
      "source": [
        " for images, labels in train_ds:\n",
        "   print(images.shape)\n",
        "   print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b5rJUiDtW5g"
      },
      "source": [
        "def train():\n",
        "    EPOCHS = 25\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        # 在下一个epoch开始时，重置评估指标\n",
        "        \n",
        "        train_loss.reset_states()\n",
        "        train_accuracy.reset_states()\n",
        "        test_loss.reset_states()\n",
        "        test_accuracy.reset_states()\n",
        "        print(\"开始训练\")\n",
        "        for images, labels in tqdm(train_ds):\n",
        "            train_step(images, labels, model)\n",
        "\n",
        "        for test_images, test_labels in tqdm(test_ds):\n",
        "            test_step(test_images, test_labels, model)\n",
        "\n",
        "        template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "        print(template.format(epoch + 1,\n",
        "                              train_loss.result(),\n",
        "                              train_accuracy.result() * 100,\n",
        "                              test_loss.result(),\n",
        "                              test_accuracy.result() * 100))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOHfhRYmyzH7"
      },
      "source": [
        "from multiprocessing import Process\n",
        "import os\n",
        "\n",
        "# 子进程要执行的代码\n",
        "def run_proc(name):\n",
        "    print('Run child process %s (%s)...' % (name, os.getpid()))\n",
        "\n",
        "if __name__=='__main__':\n",
        "    print('Parent process %s.' % os.getpid())\n",
        "    p = Process(target=run_proc, args=('test',))\n",
        "    print('Child process will start.')\n",
        "    p.start()\n",
        "    p.join()\n",
        "    print('Child process end.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zipWfnAYuSym"
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-f8TnGpE_ex"
      },
      "source": [
        "本教程训练了一个 <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer 模型</a> 用于将葡萄牙语翻译成英语。这是一个高级示例，假定您具备[文本生成（text generation）](text_generation.ipynb)和 [注意力机制（attention）](nmt_with_attention.ipynb) 的知识。\n",
        "\n",
        "Transformer 模型的核心思想是*自注意力机制（self-attention）*——能注意输入序列的不同位置以计算该序列的表示的能力。Transformer 创建了多层自注意力层（self-attetion layers）组成的堆栈，下文的*按比缩放的点积注意力（Scaled dot product attention）*和*多头注意力（Multi-head attention）*部分对此进行了说明。\n",
        "\n",
        "一个 transformer 模型用自注意力层而非 [RNNs](text_classification_rnn.ipynb) 或 [CNNs](../images/intro_to_cnns.ipynb) 来处理变长的输入。这种通用架构有一系列的优势：\n",
        "\n",
        "* 它不对数据间的时间/空间关系做任何假设。这是处理一组对象（objects）的理想选择（例如，[星际争霸单位（StarCraft units）](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)）。\n",
        "* 层输出可以并行计算，而非像 RNN 这样的序列计算。\n",
        "* 远距离项可以影响彼此的输出，而无需经过许多 RNN 步骤或卷积层（例如，参见[场景记忆 Transformer（Scene Memory Transformer）](https://arxiv.org/pdf/1903.03878.pdf)）\n",
        "* 它能学习长距离的依赖。在许多序列任务中，这是一项挑战。\n",
        "\n",
        "该架构的缺点是：\n",
        "\n",
        "* 对于时间序列，一个单位时间的输出是从*整个历史记录*计算的，而非仅从输入和当前的隐含状态计算得到。这*可能*效率较低。   \n",
        "* 如果输入*确实*有时间/空间的关系，像文本，则必须加入一些位置编码，否则模型将有效地看到一堆单词。\n",
        "\n",
        "在此 notebook 中训练完模型后，您将能输入葡萄牙语句子，得到其英文翻译。\n",
        "\n",
        "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
      ]
    }
  ]
}